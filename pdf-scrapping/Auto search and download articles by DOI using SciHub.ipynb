{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import ntpath\n",
    "from random import randint\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from captcha_solver import CaptchaSolver\n",
    "solver = CaptchaSolver(\"rucaptcha\", api_key='')\n",
    "import urllib\n",
    "import numpy\n",
    "from selenium.common.exceptions import NoSuchElementException, NoSuchWindowException, WebDriverException \n",
    "import shutil\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import threading\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchDOI:\n",
    "    def __init__(this, folder_to_download=r\"C:\\Users\\Maryia_Ivanina\\cornell_project\\pdfs_to_download\",\n",
    "                file_with_urls=\"urls_to_download.xlsx\"):\n",
    "        this.folder_to_download = folder_to_download\n",
    "        os.makedirs(folder_to_download, exist_ok=True)\n",
    "        prefs = {\"download.default_directory\": folder_to_download,\n",
    "        \"download.prompt_for_download\": False,\n",
    "        \"plugins.always_open_pdf_externally\": True}\n",
    "        \n",
    "        chromeOptions = webdriver.ChromeOptions()\n",
    "        prefs = {\"download.default_directory\" : folder_to_download}\n",
    "        chromeOptions.add_experimental_option(\"prefs\",prefs)\n",
    "        chromedriver = r\"C:\\chromedriver.exe\"\n",
    "        \n",
    "        ##save driver for later use \n",
    "        this.driver = webdriver.Chrome(executable_path=chromedriver, chrome_options=chromeOptions)\n",
    "        this.driver.delete_all_cookies()\n",
    "        \n",
    "        ## save pandas for later use \n",
    "        this.csv = pandas.read_excel(file_with_urls)\n",
    "        this.csv =  this.csv[['title', 'id','url']]\n",
    "        \n",
    "        ## place holders\n",
    "        this.title = str\n",
    "        this.cov_id = int\n",
    "        \n",
    "    def start_downloading(this):\n",
    "        ## new column\n",
    "        this.csv['automation_file_name'] = 'not found'\n",
    "\n",
    "        this.num_files_downloaded = 0\n",
    "    \n",
    "        ##start download\n",
    "        this.csv.apply(this.download, axis=1)\n",
    "        \n",
    "        this.csv.to_csv('searchDone.csv')  \n",
    "        \n",
    "    def captcha_exists(this): \n",
    "        try:\n",
    "            if this.driver.find_element_by_id('captcha'):\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError('Item not found on page') \n",
    "            return True \n",
    "        except:\n",
    "            return False \n",
    "            \n",
    "    def slove_captcha(this):\n",
    "        try:\n",
    "            src = this.driver.find_element_by_id(\"captcha\").get_attribute(\"src\") ## captcha\n",
    "            ## download captcha\n",
    "            request.urlretrieve(src, \"captcha.jpg\")\n",
    "\n",
    "            ## slove the captcha\n",
    "            solver = CaptchaSolver('rucaptcha', api_key='03a58a9552a6972819384712f3ede9e1')\n",
    "            raw_data = open('captcha.jpg', 'rb').read()\n",
    "            code = solver.solve_captcha(raw_data)\n",
    "\n",
    "            ##put code \n",
    "            this.driver.find_element_by_name(\"answer\").send_keys(code)\n",
    "            this.driver.find_element_by_xpath('//input[@value=\"Продолжить\"]').click()\n",
    "            \n",
    "            if(this.driver.find_elements_by_css_selector('#buttons > ul > li:nth-child(2) > a')): ## download button \n",
    "                time.sleep(3)\n",
    "                this.driver.find_element_by_xpath('//*[@id=\"buttons\"]/ul/li[2]/a').click() \n",
    "                time.sleep(6)\n",
    "                this.check_for_download()\n",
    "                \n",
    "            return True \n",
    "        except:\n",
    "            return False\n",
    "        \n",
    "        \n",
    "    def rename_downloaded_file(this, cov_id):\n",
    "        list_of_files = glob.glob(r\"%s\\\\*\" % this.folder_to_download) # * means all if need specific format then *.pdf\n",
    "        latest_file = max(list_of_files, key=os.path.getctime)\n",
    "\n",
    "        ## old filename\n",
    "        file_name = ntpath.basename(latest_file)\n",
    "        \n",
    "        this.title = re.sub(r'[\\\\/*?:\"<>|]',\"\",this.title)\n",
    "        this.title = this.title[:200]\n",
    "\n",
    "        ## new file name\n",
    "        #updated_file_name = latest_file.replace(file_name, \n",
    "        #                                        (\"{}_{}.pdf\".format(this.title, str(cov_id).replace('#', ''))))\n",
    "        updated_file_name = latest_file.replace(file_name, \"{}.pdf\".format(cov_id))\n",
    "        shutil.move(latest_file, updated_file_name)\n",
    "            \n",
    "        \n",
    "    def num_files_dir(this):\n",
    "        dir_files = os.listdir(this.folder_to_download)\n",
    "        return len(dir_files)\n",
    "    \n",
    "    def pdf_exists(this):\n",
    "        try:\n",
    "            this.driver.find_element_by_xpath(\"//a[contains(@href,'.pdf')]\")\n",
    "            return True \n",
    "        except NoSuchElementException:\n",
    "            return False \n",
    "    \n",
    "    def check_for_download(this):\n",
    "        if this.num_files_dir() > this.num_files_downloaded: ## there has been a file dowloaded\n",
    "            this.num_files_downloaded +=1\n",
    "            this.rename_downloaded_file(this.cov_id)\n",
    "\n",
    "            list_of_files = glob.glob(r\"%s\\\\*\" % this.folder_to_download) # * means all if need specific format then *.pdf\n",
    "            latest_file = max(list_of_files, key=os.path.getmtime)\n",
    "            file_name = ntpath.basename(latest_file)\n",
    "            \n",
    "            this.csv.loc[this.csv['id'] == this.cov_id, \"automation_file_name\"] = \"found\"\n",
    "            print(\"Downloaded \", this.cov_id)\n",
    "            this.csv.to_csv('Search_done_progress.csv') \n",
    "            \n",
    "    # watch for change in folder \n",
    "    def download_wait(this):\n",
    "        seconds = 0\n",
    "        dl_wait = True\n",
    "        while dl_wait and seconds < 120:\n",
    "            time.sleep(1)\n",
    "            dl_wait = False\n",
    "            for fname in os.listdir(r\"%s\\\\\" % this.folder_to_download):\n",
    "                if fname.endswith('.crdownload'):\n",
    "                    dl_wait = True\n",
    "            seconds += 1\n",
    "        return True\n",
    "    \n",
    "    def download(this, row, backoff=3):\n",
    "        while backoff > 0:\n",
    "            try:\n",
    "                this.download_row(row)\n",
    "                backoff = 0\n",
    "            except:\n",
    "                time.sleep(120)\n",
    "                backoff -= 1\n",
    "\n",
    "    def download_row(this, row):\n",
    "        print(row.name)\n",
    "        this.cov_id = row['id']\n",
    "        this.title = row['title']\n",
    "        if type(row['url']) == str:\n",
    "            this.driver.get('https://sci-hub.se/');\n",
    "            search_box = this.driver.find_element_by_xpath('//*[@id=\"input\"]/form/input[2]')\n",
    "            search_box.send_keys(row['url'])\n",
    "            search_box.submit()\n",
    "            \n",
    "            if(this.driver.find_elements_by_css_selector('#buttons > button')): ## download button \n",
    "                #print(this.driver.find_elements_by_css_selector('#buttons > ul > li:nth-child(2) > a'))\n",
    "                #print(this.driver.find_element_by_xpath('//*[@id=\"buttons\"]/ul/li[2]/a'))\n",
    "                this.driver.find_element_by_xpath('//*[@id=\"buttons\"]/button').click()\n",
    "\n",
    "                if this.download_wait():\n",
    "                    this.check_for_download()   \n",
    "                if this.captcha_exists():\n",
    "                    print('chapta')\n",
    "                    if this.captcha_exists():\n",
    "                        if this.slove_captcha():\n",
    "                            if this.download_wait():\n",
    "                                this.check_for_download()\n",
    "            elif(this.pdf_exists()): ## article pdf link\n",
    "                try:\n",
    "                    time.sleep(3)\n",
    "                    this.driver.find_element_by_xpath(\"//a[contains(@href,'.pdf')]\").click()\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                if this.download_wait():\n",
    "                    this.check_for_download()\n",
    "            else:  ## auto downloaded\n",
    "                if this.download_wait():\n",
    "                    this.check_for_download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maryia_Ivanina\\Anaconda3\\envs\\env-pdf-download\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: use options instead of chrome_options\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Downloaded  1\n",
      "1\n",
      "Downloaded  2\n",
      "2\n",
      "Downloaded  3\n",
      "3\n",
      "Downloaded  4\n",
      "4\n",
      "Downloaded  5\n",
      "5\n",
      "Downloaded  6\n",
      "6\n",
      "Downloaded  7\n",
      "7\n",
      "Downloaded  8\n",
      "8\n",
      "Downloaded  9\n",
      "9\n",
      "Downloaded  10\n",
      "10\n",
      "11\n",
      "11\n",
      "Downloaded  12\n",
      "12\n",
      "Downloaded  13\n",
      "13\n",
      "Downloaded  14\n",
      "14\n",
      "Downloaded  15\n",
      "15\n",
      "Downloaded  16\n",
      "16\n",
      "Downloaded  17\n",
      "17\n",
      "Downloaded  18\n",
      "18\n",
      "Downloaded  19\n",
      "19\n",
      "Downloaded  20\n"
     ]
    }
   ],
   "source": [
    "SearchDOI().start_downloading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "\n",
    "pages = []\n",
    "with open(r'C:\\Users\\Maryia_Ivanina\\cornell_project\\pdfs_to_download\\3.pdf', 'rb') as in_file:\n",
    "    parser = PDFParser(in_file)\n",
    "    doc = PDFDocument(parser)\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    for page in PDFPage.create_pages(doc):\n",
    "        output_string = StringIO()\n",
    "        device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        \n",
    "        interpreter.process_page(page)\n",
    "        pages.append(output_string.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfdocument import PDFDocument, PDFNoOutlines\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LTPage, LTChar, LTAnno, LAParams, LTTextBox, LTTextLine\n",
    "\n",
    "class PDFPageDetailedAggregator(PDFPageAggregator):\n",
    "    def __init__(self, rsrcmgr, pageno=1, laparams=None):\n",
    "        PDFPageAggregator.__init__(self, rsrcmgr, pageno=pageno, laparams=laparams)\n",
    "        self.rows = []\n",
    "        self.page_number = 0\n",
    "    def receive_layout(self, ltpage):        \n",
    "        def render(item, page_number):\n",
    "            if isinstance(item, LTPage) or isinstance(item, LTTextBox):\n",
    "                for child in item:\n",
    "                    render(child, page_number)\n",
    "            elif isinstance(item, LTTextLine):\n",
    "                child_str = ''\n",
    "                for child in item:\n",
    "                    if isinstance(child, (LTChar, LTAnno)):\n",
    "                        child_str += child.get_text()\n",
    "                child_str = ' '.join(child_str.split()).strip()\n",
    "                if child_str:\n",
    "                    row = (page_number, item.bbox[0], item.bbox[1], item.bbox[2], item.bbox[3], child_str) # bbox == (x1, y1, x2, y2)\n",
    "                    self.rows.append(row)\n",
    "                for child in item:\n",
    "                    render(child, page_number)\n",
    "            return\n",
    "        render(ltpage, self.page_number)\n",
    "        self.page_number += 1\n",
    "        self.rows = sorted(self.rows, key = lambda x: (x[0], -x[2]))\n",
    "        self.result = ltpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3508961200714111\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.layout import LAParams\n",
    "from time import time\n",
    "\n",
    "t_start = time()\n",
    "pages = []\n",
    "with open(r'C:\\Users\\Maryia_Ivanina\\cornell_project\\Auto-search-and-download-articles-by-DOI-using-SciHub-master\\Auto-search-and-download-articles-by-DOI-using-SciHub-master\\pdfs_downloaded\\1\\4327.pdf', 'rb') as fp:\n",
    "    parser = PDFParser(fp)\n",
    "    doc = PDFDocument(parser)\n",
    "\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    laparams = LAParams()\n",
    "    device = PDFPageDetailedAggregator(rsrcmgr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    \n",
    "    for pid, page in enumerate(PDFPage.create_pages(doc)):\n",
    "        try:\n",
    "            interpreter.process_page(page)\n",
    "            # receive the LTPage object for this page\n",
    "            layout = device.get_result()\n",
    "            text = []\n",
    "            \n",
    "            for lt_obj in sorted(layout, key=lambda x:(x.bbox[0] >= 300, -x.bbox[1])):\n",
    "                try:\n",
    "                    #print(lt_obj.bbox)\n",
    "                    #print(lt_obj.get_text())\n",
    "                    text.append(lt_obj.get_text())\n",
    "                except:\n",
    "                    pass\n",
    "            pages.append(\"\\n\".join(text))\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "print(time() - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.001999378204345703\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "# funding source\n",
    "text_to_use = []\n",
    "for page in range(len(pages)-1, -1, -1):\n",
    "    if \"acknowledgment\" in pages[page].lower() or \"acknowledgement\" in pages[page].lower():\n",
    "        all_text = \"\\n\\n\".join(pages[page:])\n",
    "        start = False\n",
    "        for line in all_text.split(\"\\n\"):\n",
    "            line_to_check = line\n",
    "            if line.isupper():\n",
    "                line_to_check.replace(\" \", \"\")\n",
    "            if \"acknowledgment\" in line.lower() or \"acknowledgement\" in line.lower():\n",
    "                start = True\n",
    "            if \"acknowledgment\" in line_to_check.lower() or \"acknowledgement\" in line_to_check.lower():\n",
    "                start = True\n",
    "            found_new_section = False\n",
    "            for key_word in [\"reference\", \"appendix\", \"declaration\", \"note\"]:\n",
    "                if line.lower().startswith(key_word):\n",
    "                    found_new_section = True\n",
    "                    break\n",
    "            if found_new_section:\n",
    "                if start:\n",
    "                    start = False\n",
    "                    break\n",
    "            if start:\n",
    "                text_to_use.append(line)\n",
    "        break\n",
    "print(\"\\n\".join(text_to_use))\n",
    "print(time() - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 30\n",
      "7 22\n",
      "17 16\n",
      "161 30\n",
      "184 29\n",
      "189 13\n",
      "199 29\n",
      "212 15\n",
      "286 17\n",
      "308 10\n",
      "317 24\n",
      "356 19\n",
      "360 15\n",
      "368 22\n",
      "374 26\n",
      "419 28\n",
      "420 21\n",
      "421 27\n",
      "422 18\n",
      "457 16\n",
      "473 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21, 455)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "cnt = 0\n",
    "cnt_all = 0\n",
    "for i in range(500):\n",
    "    if not os.path.exists(\"pdfs_downloaded\\%s\" % i):\n",
    "        continue\n",
    "    if i >= 20 and i <= 99:\n",
    "        continue\n",
    "    if len(os.listdir(\"pdfs_downloaded\\%s\" % i)) >= 0 and len(os.listdir(\"pdfs_downloaded\\%s\" % i)) <= 30:\n",
    "        print(i, len(os.listdir(\"pdfs_downloaded\\%s\" % i)))\n",
    "        cnt += 1\n",
    "        cnt_all += len(os.listdir(\"pdfs_downloaded\\%s\" % i))\n",
    "        #shutil.copy(\"urls_to_find_funders/%s.xlsx\" % i, \"urls_to_find_funders_left/%s.xlsx\" % i)\n",
    "        #shutil.copytree(\"pdfs_downloaded\\%s\" % i, \"pdfs\\%s\" % i)\n",
    "cnt, cnt_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33356, 39117)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_all = 0\n",
    "cnt_with_ack = 0\n",
    "for file in os.listdir(\"folder_with_ack_full/\"):\n",
    "    df = pandas.read_excel(os.path.join(\"folder_with_ack_full\", file)).fillna(\"\")\n",
    "    for i in range(len(df)):\n",
    "        if df[\"acknowledgement_part\"].values[i].strip():\n",
    "            cnt_with_ack += 1\n",
    "        cnt_all += 1\n",
    "cnt_with_ack, cnt_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8527238796431219"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_with_ack / cnt_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-pdf-download",
   "language": "python",
   "name": "env-pdf-download"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
